{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c387e7ef",
   "metadata": {},
   "source": [
    "#  문장 내의 단어들을 임베딩\n",
    "- keras.layers.Embedding 레이어 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0db507fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "# 샘플 데이터: 간단한 문장들의 모음\n",
    "sentences = [\n",
    "    \"I love machine learning\",\n",
    "    \"I love coding in Python\",\n",
    "    \"Deep learning is fun\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dc90226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I': 1,\n",
       " 'love': 2,\n",
       " 'machine': 3,\n",
       " 'learning': 4,\n",
       " 'coding': 5,\n",
       " 'in': 6,\n",
       " 'Python': 7,\n",
       " 'Deep': 8,\n",
       " 'is': 9,\n",
       " 'fun': 10}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 문장을 단어로 분할하고, 각 단어에 대한 고유한 인덱스를 생성\n",
    "word_index = {}\n",
    "\n",
    "for sentence in sentences:\n",
    "    for word in sentence.split():\n",
    "        if word not in word_index:\n",
    "            word_index[word] = len(word_index) + 1\n",
    "            \n",
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98af754a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4], [1, 2, 5, 6, 7], [8, 4, 9, 10]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장들을 단어 인덱스의 시퀀스로 변환\n",
    "sequences = [[word_index[word] for word in sentence.split()] for sentence in sentences]\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51c37c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  0],\n",
       "       [ 1,  2,  5,  6,  7],\n",
       "       [ 8,  4,  9, 10,  0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장들 중 가장 긴 것의 길이를 구함\n",
    "max_length = max([len(seq) for seq in sequences])\n",
    "\n",
    "# 모든 문장을 가장 긴 문장의 길이로 패딩\n",
    "padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bddcd17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 8)\n",
      "tf.Tensor(\n",
      "[[[ 0.01368174 -0.0356164  -0.02881208 -0.01427417 -0.03057817\n",
      "   -0.0206026   0.02760801  0.02742617]\n",
      "  [-0.04200258 -0.04269272  0.04910413 -0.00497714 -0.04756329\n",
      "   -0.03906438 -0.03248918 -0.04005836]\n",
      "  [ 0.00243111 -0.02273962  0.03214293 -0.01534401  0.03740786\n",
      "    0.04302052 -0.01578072  0.03429708]\n",
      "  [-0.03293426  0.04322648 -0.02716683 -0.02987909  0.03521569\n",
      "    0.02474227 -0.00047398  0.04210695]\n",
      "  [ 0.04034617  0.04692492 -0.03934901 -0.00058575  0.04832819\n",
      "    0.04974646  0.02799879 -0.03931914]]\n",
      "\n",
      " [[ 0.01368174 -0.0356164  -0.02881208 -0.01427417 -0.03057817\n",
      "   -0.0206026   0.02760801  0.02742617]\n",
      "  [-0.04200258 -0.04269272  0.04910413 -0.00497714 -0.04756329\n",
      "   -0.03906438 -0.03248918 -0.04005836]\n",
      "  [-0.0320858  -0.02305867 -0.04140533  0.03518803  0.04581023\n",
      "   -0.00963002 -0.04139185  0.0183456 ]\n",
      "  [-0.00585062 -0.00154204 -0.04883883 -0.03019129  0.01395775\n",
      "    0.02002696 -0.01382948  0.03004364]\n",
      "  [-0.02570194 -0.01538854 -0.02589856  0.03798615 -0.0246743\n",
      "   -0.03708439 -0.0069873   0.02924078]]\n",
      "\n",
      " [[-0.02032819 -0.01563553 -0.04126652  0.03109742 -0.00124601\n",
      "    0.00136211 -0.03133706 -0.01141561]\n",
      "  [-0.03293426  0.04322648 -0.02716683 -0.02987909  0.03521569\n",
      "    0.02474227 -0.00047398  0.04210695]\n",
      "  [-0.02023069  0.02524645  0.02554431 -0.04722159  0.04698435\n",
      "   -0.02789415  0.04884182  0.02301102]\n",
      "  [ 0.00379715  0.02171501  0.02285161  0.04534737 -0.04189718\n",
      "   -0.01814707 -0.03933766 -0.01967569]\n",
      "  [ 0.04034617  0.04692492 -0.03934901 -0.00058575  0.04832819\n",
      "    0.04974646  0.02799879 -0.03931914]]], shape=(3, 5, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Embedding 레이어 생성\n",
    "embedding_dim = 8\n",
    "embedding_layer = Embedding(input_dim=len(word_index) + 1, output_dim=embedding_dim, input_length=max_length)\n",
    "\n",
    "# 패딩된 시퀀스를 Embedding 레이어에 통과시켜 임베딩된 결과를 얻음\n",
    "embedded_sequences = embedding_layer(padded_sequences)\n",
    "\n",
    "print(embedded_sequences.shape)\n",
    "print(embedded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "691a1486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Layer Shape : (11, 8)\n",
      "Embedding Layer Weights (Word Embeddings):\n",
      " [[ 0.04034617  0.04692492 -0.03934901 -0.00058575  0.04832819  0.04974646\n",
      "   0.02799879 -0.03931914]\n",
      " [ 0.01368174 -0.0356164  -0.02881208 -0.01427417 -0.03057817 -0.0206026\n",
      "   0.02760801  0.02742617]\n",
      " [-0.04200258 -0.04269272  0.04910413 -0.00497714 -0.04756329 -0.03906438\n",
      "  -0.03248918 -0.04005836]\n",
      " [ 0.00243111 -0.02273962  0.03214293 -0.01534401  0.03740786  0.04302052\n",
      "  -0.01578072  0.03429708]\n",
      " [-0.03293426  0.04322648 -0.02716683 -0.02987909  0.03521569  0.02474227\n",
      "  -0.00047398  0.04210695]\n",
      " [-0.0320858  -0.02305867 -0.04140533  0.03518803  0.04581023 -0.00963002\n",
      "  -0.04139185  0.0183456 ]\n",
      " [-0.00585062 -0.00154204 -0.04883883 -0.03019129  0.01395775  0.02002696\n",
      "  -0.01382948  0.03004364]\n",
      " [-0.02570194 -0.01538854 -0.02589856  0.03798615 -0.0246743  -0.03708439\n",
      "  -0.0069873   0.02924078]\n",
      " [-0.02032819 -0.01563553 -0.04126652  0.03109742 -0.00124601  0.00136211\n",
      "  -0.03133706 -0.01141561]\n",
      " [-0.02023069  0.02524645  0.02554431 -0.04722159  0.04698435 -0.02789415\n",
      "   0.04884182  0.02301102]\n",
      " [ 0.00379715  0.02171501  0.02285161  0.04534737 -0.04189718 -0.01814707\n",
      "  -0.03933766 -0.01967569]]\n",
      "\n",
      "\n",
      "Embedding for 'love':\n",
      " [-0.04200258 -0.04269272  0.04910413 -0.00497714 -0.04756329 -0.03906438\n",
      " -0.03248918 -0.04005836]\n"
     ]
    }
   ],
   "source": [
    "# Embedding 레이어의 가중치 (단어 임베딩 행렬) 출력\n",
    "embeddings = embedding_layer.get_weights()[0]\n",
    "print(\"Embedding Layer Shape :\", embeddings.shape)\n",
    "print(\"Embedding Layer Weights (Word Embeddings):\\n\", embeddings)\n",
    "print()\n",
    "\n",
    "# 예: 'love'라는 단어의 임베딩 벡터를 출력\n",
    "print(\"\\nEmbedding for 'love':\\n\", embeddings[word_index['love']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf45463",
   "metadata": {},
   "source": [
    "0은 보통 패딩을 나타내는 인덱스로 사용됩니다. 결과적으로, Embedding 레이어의 가중치 행렬의 크기는 (고유한 단어 수 + 1, 임베딩 벡터의 차원수)가 되므로, (11, 8)이 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481bdef6",
   "metadata": {},
   "source": [
    "### 위에서 만들어진 Embedding Layer 는 현재 초기값으로 채워져 있는 상태이고 Large Language Model의 학습 과정에서 최적의 값으로 update 되는 과정을 거치게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c316205",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
